{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dask.distributed import Client, LocalCluster, fire_and_forget\n",
    "\n",
    "from core.config import cfg\n",
    "from core.benchmark import create_benchmark_configs, run_benchmark_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_benchmark(benchmark, output_root=None, sample=None):\n",
    "    \"\"\"\n",
    "    Executes a given benchmark and saves the results in csv format if the output_root argument is specified.\n",
    "    The results are saved according to the following folder structure: output_root/dataset/processing/target/features/model.\n",
    "    \"\"\"\n",
    "    \n",
    "    result, ys = run_benchmark_cv(benchmark, n_splits=10, sample=sample, group_column=('diagnosis_code' if benchmark.dataset == \"tdbrain\" else None))\n",
    "\n",
    "    if output_root is not None:  # save results\n",
    "        save_dir = Path(output_root) / benchmark.dataset / benchmark.processing / benchmark.target / benchmark.features / benchmark.model\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        result.to_csv(save_dir / 'results.csv')\n",
    "        ys.to_csv(save_dir / 'ys.csv')\n",
    "\n",
    "    return result, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Dask Cluster\n",
    "# Note: Feel free to configure your own dask cluster if you have access to more\n",
    "# computatial resources. For example an LSFCluster with multiple GPUs.\n",
    "\n",
    "gpu_available = False\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create benchmark configs\n",
    "\n",
    "# Add preprocessing level benchmarks\n",
    "benchmarks = create_benchmark_configs(\n",
    "    datasets = [\"TDBRAIN\", \"TUAB\"],\n",
    "    models = [\"naive_pca\", \"log_diag_pca\", \"spoc_log\", \"riemann\", \"shallow\"],\n",
    "    features = [\"meeglet\", \"raw\"],\n",
    "    processings = [\"preproc_minimal\", \"preproc_autoreject\", \"preproc_autoreject_ica\"],\n",
    "    targets = [\"age\", \"sex\"]\n",
    ")\n",
    "\n",
    "# Add Aux channel benchmarks\n",
    "benchmarks += create_benchmark_configs(\n",
    "    datasets = [\"TDBRAIN\"],\n",
    "    models = [\"naive_pca\", \"log_diag_pca\", \"spoc_log\", \"riemann\", \"shallow\"],\n",
    "    features = [\"meeglet\", \"raw\"],\n",
    "    processings = [\"aux_and_eeg_channels\", \"aux_channels\", \"aux_ocular_channels\", \"aux_non_oculuar_channels\"],\n",
    "    targets = [\"age\", \"sex\"]\n",
    ")\n",
    "\n",
    "# Add ICA subspace benchmarks\n",
    "benchmarks += create_benchmark_configs(\n",
    "    datasets = [\"TDBRAIN\", \"TUAB\"],\n",
    "    models = [\"naive_pca\", \"log_diag_pca\", \"spoc_log\", \"riemann\", \"shallow\"],\n",
    "    features = [\"meeglet\", \"raw\"],\n",
    "    processings = [\"ica_artifact_subspace\", \"ica_ocular_artifact_subspace\", \"ica_muscle_artifact_subspace\", \"ica_other_artifact_subspace\"],\n",
    "    targets = [\"age\", \"sex\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: In version 3.0.1 of the TUAB dataset, the age of subjects with age >= 90 has been set to 999.\n",
    "# If you are using this version of TUAB, the following should be used to exclude these subjects for\n",
    "# the age prediction task.\n",
    "#\n",
    "# from fastcore.transform import Transform, Pipeline\n",
    "# from copy import deepcopy\n",
    "#\n",
    "# for benchmark in benchmarks:\n",
    "#     if (benchmark.dataset == \"TUAB\") and (benchmark.target == \"age\"):\n",
    "#         assert isinstance(benchmark.filter_func, Pipeline)\n",
    "#         new_filter_func = deepcopy(benchmark.filter_func)\n",
    "#         new_filter_func.add(Transform(lambda df: df[df[\"age\"] < 90]))\n",
    "#         benchmark.filter_func = new_filter_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit jobs to cluster\n",
    "for bm in benchmarks:\n",
    "    if gpu_available and bm.features == \"raw\":  # request GPU for models operating on raw data\n",
    "        fire_and_forget(client.submit(compute_benchmark, bm, output_root=cfg[\"RESULTS\"][\"results_path\"], resources={'GPU': 1}))\n",
    "    else:\n",
    "        fire_and_forget(client.submit(compute_benchmark, bm, output_root=cfg[\"RESULTS\"][\"results_path\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The client dashboard can be used to monitor progress\n",
    "client"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg-biomarker-paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
